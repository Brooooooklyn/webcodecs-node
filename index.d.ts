/* auto-generated by NAPI-RS */
/* eslint-disable */
/**
 * AudioData - represents uncompressed audio data
 *
 * This is a WebCodecs-compliant AudioData implementation backed by FFmpeg.
 */
export declare class AudioData {
  /** Create a new AudioData from raw sample data */
  constructor(data: Uint8Array, init: AudioDataInit)
  /** Get sample format */
  get format(): AudioSampleFormat | null
  /** Get sample rate in Hz */
  get sampleRate(): number
  /** Get number of frames (samples per channel) */
  get numberOfFrames(): number
  /** Get number of channels */
  get numberOfChannels(): number
  /** Get duration in microseconds */
  get duration(): number
  /** Get timestamp in microseconds */
  get timestamp(): number
  /** Get the buffer size required for allocationSize */
  allocationSize(options?: AudioDataCopyToOptions | undefined | null): number
  /** Copy audio data to a buffer */
  copyTo(destination: Uint8Array, options?: AudioDataCopyToOptions | undefined | null): void
  /** Create a copy of this AudioData */
  clone(): AudioData
  /** Close and release resources */
  close(): void
}

/**
 * AudioDecoder - WebCodecs-compliant audio decoder
 *
 * Decodes EncodedAudioChunk objects into AudioData objects using FFmpeg.
 *
 * Note: This implementation uses a synchronous output queue model instead of
 * callbacks for simpler integration. Use `takeDecodedAudio()` to retrieve
 * decoded output after calling `decode()` or `flush()`.
 */
export declare class AudioDecoder {
  /** Create a new AudioDecoder */
  constructor()
  /** Get decoder state */
  get state(): CodecState
  /** Get number of pending output audio data objects */
  get decodeQueueSize(): number
  /** Configure the decoder */
  configure(config: AudioDecoderConfig): void
  /** Decode an encoded audio chunk */
  decode(chunk: EncodedAudioChunk): void
  /** Flush the decoder and return all remaining audio data */
  flush(): void
  /** Take all decoded audio from the output queue */
  takeDecodedAudio(): Array<AudioData>
  /** Check if there are any pending decoded audio data */
  hasOutput(): boolean
  /** Take the next decoded audio data from the output queue (if any) */
  takeNextAudio(): AudioData | null
  /** Reset the decoder */
  reset(): void
  /** Close the decoder */
  close(): void
  /** Check if a configuration is supported */
  static isConfigSupported(config: AudioDecoderConfig): AudioDecoderSupport
}

/**
 * AudioEncoder - WebCodecs-compliant audio encoder
 *
 * Encodes AudioData objects into EncodedAudioChunk objects using FFmpeg.
 *
 * Note: This implementation uses a synchronous output queue model instead of
 * callbacks for simpler integration. Use `takeEncodedChunks()` to retrieve
 * encoded output after calling `encode()` or `flush()`.
 */
export declare class AudioEncoder {
  /** Create a new AudioEncoder */
  constructor()
  /** Get encoder state */
  get state(): CodecState
  /** Get number of pending output chunks */
  get encodeQueueSize(): number
  /** Configure the encoder */
  configure(config: AudioEncoderConfig): void
  /** Encode audio data */
  encode(data: AudioData): void
  /** Flush the encoder and return all remaining chunks */
  flush(): void
  /** Take all encoded chunks from the output queue */
  takeEncodedChunks(): Array<EncodedAudioChunk>
  /** Check if there are any pending encoded chunks */
  hasOutput(): boolean
  /** Take the next encoded chunk from the output queue (if any) */
  takeNextChunk(): EncodedAudioChunk | null
  /** Reset the encoder */
  reset(): void
  /** Close the encoder */
  close(): void
  /** Check if a configuration is supported */
  static isConfigSupported(config: AudioEncoderConfig): AudioEncoderSupport
}

/**
 * EncodedAudioChunk - represents encoded audio data
 *
 * This is a WebCodecs-compliant EncodedAudioChunk implementation.
 */
export declare class EncodedAudioChunk {
  /** Create a new EncodedAudioChunk */
  constructor(init: EncodedAudioChunkInit)
  /** Get the chunk type */
  get type(): EncodedAudioChunkType
  /** Get the timestamp in microseconds */
  get timestamp(): number
  /** Get the duration in microseconds */
  get duration(): number | null
  /** Get the byte length of the encoded data */
  get byteLength(): number
  /** Copy the encoded data to a Uint8Array */
  copyTo(destination: Uint8Array): void
  /** Get the raw data as a Uint8Array (extension, not in spec) */
  get data(): Uint8Array
  /** Close and release resources */
  close(): void
}

/**
 * EncodedVideoChunk - represents encoded video data
 *
 * This is a WebCodecs-compliant EncodedVideoChunk implementation.
 */
export declare class EncodedVideoChunk {
  /** Create a new EncodedVideoChunk */
  constructor(init: EncodedVideoChunkInit)
  /** Get the chunk type */
  get type(): EncodedVideoChunkType
  /** Get the timestamp in microseconds */
  get timestamp(): number
  /** Get the duration in microseconds */
  get duration(): number | null
  /** Get the byte length of the encoded data */
  get byteLength(): number
  /** Copy the encoded data to a Uint8Array */
  copyTo(destination: Uint8Array): void
  /** Get the raw data as a Buffer (extension, not in spec) */
  getData(): Buffer
}

/**
 * VideoDecoder - WebCodecs-compliant video decoder
 *
 * Decodes EncodedVideoChunk objects into VideoFrame objects using FFmpeg.
 *
 * Note: This implementation uses a synchronous output queue model instead of
 * callbacks for simpler integration. Use `takeDecodedFrames()` to retrieve
 * decoded output after calling `decode()` or `flush()`.
 */
export declare class VideoDecoder {
  /** Create a new VideoDecoder */
  constructor()
  /** Get decoder state */
  get state(): CodecState
  /** Get number of pending output frames */
  get decodeQueueSize(): number
  /** Configure the decoder */
  configure(config: VideoDecoderConfig): void
  /** Decode an encoded video chunk */
  decode(chunk: EncodedVideoChunk): void
  /** Flush the decoder and return all remaining frames */
  flush(): void
  /** Take all decoded frames from the output queue */
  takeDecodedFrames(): Array<VideoFrame>
  /** Check if there are any pending decoded frames */
  hasOutput(): boolean
  /** Take the next decoded frame from the output queue (if any) */
  takeNextFrame(): VideoFrame | null
  /** Reset the decoder */
  reset(): void
  /** Close the decoder */
  close(): void
  /** Check if a configuration is supported */
  static isConfigSupported(config: VideoDecoderConfig): VideoDecoderSupport
}

/**
 * VideoEncoder - WebCodecs-compliant video encoder
 *
 * Encodes VideoFrame objects into EncodedVideoChunk objects using FFmpeg.
 *
 * Note: This implementation uses a synchronous output queue model instead of
 * callbacks for simpler integration. Use `takeEncodedChunks()` to retrieve
 * encoded output after calling `encode()` or `flush()`.
 */
export declare class VideoEncoder {
  /** Create a new VideoEncoder (queue-based mode) */
  constructor()
  /**
   * Create a VideoEncoder with callbacks (WebCodecs spec compliant mode)
   *
   * In this mode, encoded chunks are delivered via the output callback
   * instead of being queued for retrieval. Errors are reported via the
   * error callback and the encoder transitions to the Closed state.
   *
   * Example:
   * ```javascript
   * const encoder = VideoEncoder.withCallbacks(
   *   (chunk, metadata) => { /* handle output */ },
   *   (error) => { /* handle error */ }
   * );
   * ```
   */
  static withCallbacks(output: ((err: Error | null, arg0: EncodedVideoChunk, arg1: EncodedVideoChunkMetadata) => any), error: ((err: Error | null, arg: string) => any)): VideoEncoder
  /** Get encoder state */
  get state(): CodecState
  /** Get number of pending output chunks */
  get encodeQueueSize(): number
  /** Configure the encoder */
  configure(config: VideoEncoderConfig): void
  /** Encode a frame */
  encode(frame: VideoFrame, options?: VideoEncoderEncodeOptions | undefined | null): void
  /** Flush the encoder and return all remaining chunks */
  flush(): void
  /**
   * Take all encoded chunks from the output queue
   *
   * Returns an array of [chunk, metadata] pairs
   */
  takeEncodedChunks(): Array<EncodedVideoChunk>
  /** Check if there are any pending encoded chunks */
  hasOutput(): boolean
  /** Take the next encoded chunk from the output queue (if any) */
  takeNextChunk(): EncodedVideoChunk | null
  /** Reset the encoder */
  reset(): void
  /** Close the encoder */
  close(): void
  /** Check if a configuration is supported */
  static isConfigSupported(config: VideoEncoderConfig): VideoEncoderSupport
}

/**
 * VideoFrame - represents a frame of video
 *
 * This is a WebCodecs-compliant VideoFrame implementation backed by FFmpeg.
 */
export declare class VideoFrame {
  /** Create a new VideoFrame from raw data */
  constructor(data: Buffer, init: VideoFrameInit)
  /** Get the pixel format */
  get format(): VideoPixelFormat | null
  /** Get the coded width in pixels */
  get codedWidth(): number
  /** Get the coded height in pixels */
  get codedHeight(): number
  /** Get the display width in pixels */
  get displayWidth(): number
  /** Get the display height in pixels */
  get displayHeight(): number
  /** Get the presentation timestamp in microseconds */
  get timestamp(): number
  /** Get the duration in microseconds */
  get duration(): number | null
  /** Get the color space parameters */
  get colorSpace(): VideoColorSpace
  /** Calculate the allocation size needed for copyTo */
  allocationSize(options?: VideoFrameCopyToOptions | undefined | null): number
  /** Copy frame data to a Uint8Array */
  copyTo(destination: Uint8Array): void
  /** Clone this VideoFrame */
  clone(): VideoFrame
  /** Close and release resources */
  close(): void
}

/** Options for copyTo operation */
export interface AudioDataCopyToOptions {
  /** The index of the audio plane to copy */
  planeIndex: number
  /** The offset in frames to start copying from (optional) */
  frameOffset?: number
  /** The number of frames to copy (optional, defaults to all remaining) */
  frameCount?: number
  /** Target format for conversion (optional) */
  format?: AudioSampleFormat
}

/** Options for creating an AudioData */
export interface AudioDataInit {
  /** Sample format */
  format: AudioSampleFormat
  /** Sample rate in Hz */
  sampleRate: number
  /** Number of frames (samples per channel) */
  numberOfFrames: number
  /** Number of channels */
  numberOfChannels: number
  /** Timestamp in microseconds */
  timestamp: number
}

/** Audio decoder configuration (WebCodecs spec) */
export interface AudioDecoderConfig {
  /** Codec string (e.g., "mp4a.40.2" for AAC-LC, "opus") */
  codec: string
  /** Sample rate in Hz (optional, may be in description) */
  sampleRate?: number
  /** Number of channels (optional, may be in description) */
  numberOfChannels?: number
  /** Codec-specific description data (e.g., AudioSpecificConfig for AAC) */
  description?: Buffer
}

/** Decoder configuration output (for passing to decoder) */
export interface AudioDecoderConfigOutput {
  /** Codec string */
  codec: string
  /** Sample rate */
  sampleRate?: number
  /** Number of channels */
  numberOfChannels?: number
  /** Codec description (e.g., AudioSpecificConfig for AAC) */
  description?: Buffer
}

/** Audio decoder support information */
export interface AudioDecoderSupport {
  /** Whether the configuration is supported */
  supported: boolean
  /** The configuration that was tested */
  config: AudioDecoderConfig
}

/** Audio encoder configuration (WebCodecs spec) */
export interface AudioEncoderConfig {
  /** Codec string (e.g., "mp4a.40.2" for AAC-LC, "opus") */
  codec: string
  /** Sample rate in Hz */
  sampleRate?: number
  /** Number of channels */
  numberOfChannels?: number
  /** Target bitrate in bits per second */
  bitrate?: number
  /** Opus-specific: complexity (0-10) */
  complexity?: number
  /** Opus-specific: application type ("voip", "audio", "lowdelay") */
  opusApplication?: string
  /** Opus-specific: signal type ("auto", "music", "voice") */
  opusSignal?: string
  /** Opus-specific: frame duration preference in microseconds */
  opusFrameDuration?: number
  /** AAC-specific: format ("aac", "adts") */
  aacFormat?: string
}

/** Encode options for audio */
export interface AudioEncoderEncodeOptions {

}

/** Audio encoder support information */
export interface AudioEncoderSupport {
  /** Whether the configuration is supported */
  supported: boolean
  /** The configuration that was tested */
  config: AudioEncoderConfig
}

/** Audio sample format (WebCodecs spec) */
export declare const enum AudioSampleFormat {
  /** Unsigned 8-bit integer samples, interleaved */
  U8 = 'U8',
  /** Signed 16-bit integer samples, interleaved */
  S16 = 'S16',
  /** Signed 32-bit integer samples, interleaved */
  S32 = 'S32',
  /** 32-bit float samples, interleaved */
  F32 = 'F32',
  /** Unsigned 8-bit integer samples, planar */
  U8Planar = 'U8Planar',
  /** Signed 16-bit integer samples, planar */
  S16Planar = 'S16Planar',
  /** Signed 32-bit integer samples, planar */
  S32Planar = 'S32Planar',
  /** 32-bit float samples, planar */
  F32Planar = 'F32Planar'
}

/** Encode configuration for AV1 */
export interface Av1EncoderConfig {
  /** AV1 profile: 0 (Main), 1 (High), 2 (Professional) */
  profile?: number
  /** CPU usage preset (0 = slowest/best quality, 8 = fastest) */
  cpuUsed?: number
  /** Tile columns (1, 2, 4, 8, 16, 32, 64) */
  tileColumns?: number
  /** Tile rows */
  tileRows?: number
  /** CQ level for quantizer mode (0-63, lower = better quality) */
  cqLevel?: number
  /** Enable screen content coding tools */
  screenContent?: boolean
}

/** Decode configuration for AVC (H.264) */
export interface AvcDecoderConfig {
  /** AVC configuration record (avcC box content) */
  avcC?: Buffer
}

/** Encode configuration for AVC (H.264) */
export interface AvcEncoderConfig {
  /** AVC profile (e.g., "baseline", "main", "high") */
  profile?: string
  /** AVC level (e.g., "3.0", "4.0", "5.1") */
  level?: string
  /** Output format: "annexb" or "avc" */
  format?: string
}

/** Encoder state */
export declare const enum CodecState {
  /** Encoder not configured */
  Unconfigured = 'Unconfigured',
  /** Encoder configured and ready */
  Configured = 'Configured',
  /** Encoder closed */
  Closed = 'Closed'
}

/** Options for creating an EncodedAudioChunk */
export interface EncodedAudioChunkInit {
  /** Chunk type (key or delta) */
  type: EncodedAudioChunkType
  /** Timestamp in microseconds */
  timestamp: number
  /** Duration in microseconds (optional) */
  duration?: number
  /** Encoded data */
  data: Buffer
}

/** Output callback metadata for audio */
export interface EncodedAudioChunkMetadata {
  /** Decoder configuration for this chunk */
  decoderConfig?: AudioDecoderConfigOutput
}

/** Type of encoded audio chunk */
export declare const enum EncodedAudioChunkType {
  /** Key chunk - can be decoded independently */
  Key = 'Key',
  /** Delta chunk - depends on previous chunks */
  Delta = 'Delta'
}

/** Options for creating an EncodedVideoChunk */
export interface EncodedVideoChunkInit {
  /** Chunk type (key or delta) */
  type: EncodedVideoChunkType
  /** Timestamp in microseconds */
  timestamp: number
  /** Duration in microseconds (optional) */
  duration?: number
  /** Encoded data */
  data: Buffer
}

/** Output callback metadata */
export interface EncodedVideoChunkMetadata {
  /** Decoder configuration for this chunk (only present for keyframes) */
  decoderConfig?: VideoDecoderConfigOutput
}

/** Type of encoded video chunk */
export declare const enum EncodedVideoChunkType {
  /** Keyframe - can be decoded independently */
  Key = 'Key',
  /** Delta frame - depends on previous frames */
  Delta = 'Delta'
}

/** Get available hardware accelerators (only those that can be used) */
export declare function getAvailableHardwareAccelerators(): Array<string>

/** Get list of all known hardware accelerators and their availability */
export declare function getHardwareAccelerators(): Array<HardwareAccelerator>

/** Get the preferred hardware accelerator for the current platform */
export declare function getPreferredHardwareAccelerator(): string | null

/** Hardware accelerator information */
export interface HardwareAccelerator {
  /** Internal name (e.g., "videotoolbox", "cuda", "vaapi") */
  name: string
  /** Human-readable description */
  description: string
  /** Whether this accelerator is available on this system */
  available: boolean
}

/** Encode configuration for HEVC (H.265) */
export interface HevcEncoderConfig {
  /** HEVC profile: "main", "main10", "main-still-picture", "rext" */
  profile?: string
  /** Tier: "main" or "high" */
  tier?: string
  /** Level (e.g., "4.0", "5.1", "6.2") */
  level?: string
  /** Encoding preset: "ultrafast", "superfast", "veryfast", "faster", "fast", "medium", "slow", "slower", "veryslow", "placebo" */
  preset?: string
  /** Tuning: "psnr", "ssim", "grain", "zerolatency", "fastdecode" */
  tune?: string
}

/** Check if a specific hardware accelerator is available */
export declare function isHardwareAcceleratorAvailable(name: string): boolean

/** Video color space parameters (WebCodecs spec) */
export interface VideoColorSpace {
  /** Color primaries (e.g., "bt709", "bt2020") */
  primaries?: string
  /** Transfer function (e.g., "bt709", "srgb", "pq", "hlg") */
  transfer?: string
  /** Matrix coefficients (e.g., "bt709", "bt2020-ncl") */
  matrix?: string
  /** Full range flag */
  fullRange?: boolean
}

/** Video decoder configuration (WebCodecs spec) */
export interface VideoDecoderConfig {
  /** Codec string (e.g., "avc1.42001E", "vp8", "vp09.00.10.08") */
  codec: string
  /** Coded width in pixels (optional for some codecs) */
  codedWidth?: number
  /** Coded height in pixels (optional for some codecs) */
  codedHeight?: number
  /** Display aspect width */
  displayAspectWidth?: number
  /** Display aspect height */
  displayAspectHeight?: number
  /** Color space parameters */
  colorSpace?: VideoColorSpace
  /** Hardware acceleration preference */
  hardwareAcceleration?: string
  /** Optimization preference: "prefer-accuracy" or "prefer-speed" */
  optimizeForLatency?: boolean
  /** Codec-specific description data (e.g., avcC for H.264) */
  description?: Buffer
}

/** Decoder configuration output (for passing to decoder) */
export interface VideoDecoderConfigOutput {
  /** Codec string */
  codec: string
  /** Coded width */
  codedWidth?: number
  /** Coded height */
  codedHeight?: number
  /** Codec description (e.g., avcC for H.264) */
  description?: Buffer
}

/** Result of isConfigSupported */
export interface VideoDecoderSupport {
  /** Whether the configuration is supported */
  supported: boolean
  /** The configuration that was checked (codec only for simplicity) */
  codec: string
}

/** Video encoder configuration (WebCodecs spec) */
export interface VideoEncoderConfig {
  /** Codec string (e.g., "avc1.42001E", "vp8", "vp09.00.10.08") */
  codec: string
  /** Coded width in pixels */
  width: number
  /** Coded height in pixels */
  height: number
  /** Display width (optional, defaults to width) */
  displayWidth?: number
  /** Display height (optional, defaults to height) */
  displayHeight?: number
  /** Target bitrate in bits per second */
  bitrate?: number
  /** Framerate */
  framerate?: number
  /** Hardware acceleration preference */
  hardwareAcceleration?: string
  /** Latency mode: "quality" or "realtime" */
  latencyMode?: string
  /** Bitrate mode: "constant", "variable", "quantizer" */
  bitrateMode?: string
  /** AVC-specific configuration (H.264) */
  avc?: AvcEncoderConfig
  /** VP9-specific configuration */
  vp9?: Vp9EncoderConfig
  /** AV1-specific configuration */
  av1?: Av1EncoderConfig
  /** HEVC-specific configuration (H.265) */
  hevc?: HevcEncoderConfig
  /** Alpha handling: "discard" or "keep" */
  alpha?: string
  /** Scalability mode (SVC) - e.g., "L1T1", "L1T2", "L1T3" */
  scalabilityMode?: string
}

/** Encode options */
export interface VideoEncoderEncodeOptions {
  /** Force this frame to be a keyframe */
  keyFrame?: boolean
}

/** Result of isConfigSupported */
export interface VideoEncoderSupport {
  /** Whether the configuration is supported */
  supported: boolean
  /** The configuration that was checked */
  config: VideoEncoderConfig
}

/** Options for copyTo operation */
export interface VideoFrameCopyToOptions {
  /** Target pixel format (for format conversion) */
  format?: VideoPixelFormat
  /** Region to copy (not yet implemented) */
  rect?: VideoFrameRect
}

/** Options for creating a VideoFrame */
export interface VideoFrameInit {
  /** Pixel format */
  format: VideoPixelFormat
  /** Coded width in pixels */
  codedWidth: number
  /** Coded height in pixels */
  codedHeight: number
  /** Timestamp in microseconds */
  timestamp: number
  /** Duration in microseconds (optional) */
  duration?: number
  /** Display width (defaults to coded_width) */
  displayWidth?: number
  /** Display height (defaults to coded_height) */
  displayHeight?: number
  /** Color space parameters */
  colorSpace?: VideoColorSpace
}

/** Rectangle for specifying a region */
export interface VideoFrameRect {
  x: number
  y: number
  width: number
  height: number
}

/** Video pixel format (WebCodecs spec) */
export declare const enum VideoPixelFormat {
  /** Planar YUV 4:2:0, 12bpp, (1 Cr & Cb sample per 2x2 Y samples) */
  I420 = 'I420',
  /** Planar YUV 4:2:0, 12bpp, with alpha plane */
  I420A = 'I420A',
  /** Planar YUV 4:2:2, 16bpp */
  I422 = 'I422',
  /** Planar YUV 4:4:4, 24bpp */
  I444 = 'I444',
  /** Semi-planar YUV 4:2:0, 12bpp (Y plane + interleaved UV) */
  NV12 = 'NV12',
  /** RGBA 32bpp */
  RGBA = 'RGBA',
  /** RGBX 32bpp (alpha ignored) */
  RGBX = 'RGBX',
  /** BGRA 32bpp */
  BGRA = 'BGRA',
  /** BGRX 32bpp (alpha ignored) */
  BGRX = 'BGRX'
}

/** Encode configuration for VP9 */
export interface Vp9EncoderConfig {
  /** VP9 profile: 0 (8-bit 4:2:0), 1 (8-bit 4:2:2/4:4:4), 2 (10/12-bit 4:2:0), 3 (10/12-bit 4:2:2/4:4:4) */
  profile?: number
  /** Encoding speed preset (0 = best quality/slowest, 8 = fastest) */
  speed?: number
  /** Tile columns (log2 value: 0-6) */
  tileColumns?: number
  /** Tile rows (log2 value: 0-2) */
  tileRows?: number
  /** Enable row-based multithreading */
  rowMt?: boolean
  /** Keyframe placement mode: "auto", "disabled" */
  keyframeMode?: string
}
